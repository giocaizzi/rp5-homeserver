# Ollama - AI model serving
server {
    listen 443 ssl;
    http2 on;
    server_name ollama.home;

    include snippets/ssl-params.conf;
    include snippets/error-503.conf;

    # Increase timeouts for AI model operations
    proxy_read_timeout 300s;
    proxy_connect_timeout 30s;
    proxy_send_timeout 30s;

    location / {
        limit_req zone=general burst=10 nodelay;
        set $upstream $backend;
        proxy_pass http://$upstream;
        include snippets/proxy-headers.conf;
        
        # Support for streaming responses
        proxy_buffering off;
        proxy_cache off;
    }
}
